learner_data_set_means$data_set = PrettifyFeatureSetNames(learner_data_set_means$data_set)
mat = cbind(
learner_data_set_means[learner_data_set_means$base_learner=='knn','mean_score'],
learner_data_set_means[learner_data_set_means$base_learner=='rir','mean_score'],
learner_data_set_means[learner_data_set_means$base_learner=='svm','mean_score'],
learner_data_set_means[learner_data_set_means$base_learner=='nnr','mean_score'],
learner_data_set_means[learner_data_set_means$base_learner=='rfr','mean_score'])
# Reorder so the heatmap is a bit more organized
order = c(1, #seq
2,4,6,3,5, # nuc
9,8,7, #cod
28,25,24, # aa
29,27,26, # aap
23, # poly proline
31,32,33, # rpf
10,12,16,14,11,13,15, # struct
19,22,21,20, # halflife
30, # rna abdnc
17,18, # sorf
34,35,36,37,38,39 # comp
)
mat = mat[rev(order),]
data_set_names = rev(as.list(unique(learner_data_set_means$data_set))[order])
# STYLE
f <- list(
family = "Lucida Console",
size = 12
)
x = list(
title = "Machine Learners",
titlefont = list(size=16, color='black')
)
y <- list(
title = "Feature Sets",
titlefont = list(size=16, color='black')
)
colfunc <- colorRampPalette(c("#FFFFFF", "#000000"))
p_all = plot_ly(x=list('KNN','RIR','SVM','NNR','RFR'), z = mat, type = "heatmap",
y=data_set_names,
colors=colfunc(100)[round(100 * min(mat) / max(mat)):round((max(unlist(mat)) / max(unlist(mat))) * 100)],
width=400, height=(20*nrow(mat))+20, size=0.3) %>%
layout(margin=list(b=20, l=140, r=0, t=0, pad=0, autoexpand=T), font=f)
print(p_all)
export(p_all, file="figures/heatmap_full.pdf", vwidth=400, vheight=(20*nrow(mat))+20, delay=0)
scr = readRDS('data/ml_scores_filtered2.RObject')
scr = scr[!grepl('\\_p[0-9]{1,2}', scr$data_set),] # Remove all results from the permutation test
scr[scr$test_score < 0, 'test_score'] = 0 # Set the cut off for the plot at 0 (so as good as, or worse than random)
learner_data_set_means = as.data.frame(scr %>%
group_by(base_learner, data_set) %>%
summarize(mean_score = mean(test_score)
, stdev = sd(test_score)
, count = n()))
learner_data_set_means$data_set = PrettifyFeatureSetNames(learner_data_set_means$data_set)
mat = cbind(
learner_data_set_means[learner_data_set_means$base_learner=='knn','mean_score'],
learner_data_set_means[learner_data_set_means$base_learner=='rir','mean_score'],
learner_data_set_means[learner_data_set_means$base_learner=='svm','mean_score'],
learner_data_set_means[learner_data_set_means$base_learner=='nnr','mean_score'],
learner_data_set_means[learner_data_set_means$base_learner=='rfr','mean_score'])
# Reorder so the heatmap is a bit more organized
order = c(1, #seq
2,4,6,3,5, # nuc
9,8,7, #cod
28,25,24, # aa
29,27,26, # aap
23, # poly proline
31,32,33, # rpf
10,12,16,14,11,13,15, # struct
19,22,21,20, # halflife
30, # rna abdnc
17,18, # sorf
34,35,36,37,38,39 # comp
)
mat = mat[rev(order),]
data_set_names = rev(as.list(unique(learner_data_set_means$data_set))[order])
# STYLE
f <- list(
family = "Lucida Console",
size = 12
)
x = list(
title = "Machine Learners",
titlefont = list(size=16, color='black')
)
y <- list(
title = "Feature Sets",
titlefont = list(size=16, color='black')
)
colfunc <- colorRampPalette(c("#FFFFFF", "#000000"))
p_all = plot_ly(x=list('KNN','RIR','SVM','NNR','RFR'), z = mat, type = "heatmap",
y=data_set_names,
colors=colfunc(100)[round(100 * min(mat) / max(mat)):round((max(unlist(mat)) / max(unlist(mat))) * 100)],
width=400, height=(20*nrow(mat))+20, size=0.3) %>%
layout(margin=list(b=20, l=140, r=0, t=0, pad=0, autoexpand=T), font=f)
print(p_all)
export(p_all, file="figures/heatmap_full.pdf", vwidth=400, vheight=(20*nrow(mat))+20, delay=0)
View(learner_data_set_means)
View(scr)
mean(0.1904761742, 0.1825558781, 0.1672704235, 0.1988740095, 0.1831486857, 0.1580847569, 0.2006759530, 0.1993494902, 0.2136099102, 0.1657473918)
mean(0.1717396877, 0.1549893311, 0.1765587853, 0.1720607392, 0.1952447037, 0.1890451919, 0.1680679084, 0.1886321105,0.1727215485,0.2079468780)
mean(0.1717396877, 0.1549893311, 0.1765587853, 0.1720607392, 0.1952447037, 0.1890451919, 0.1680679084, 0.1886321105,0.1727215485,0.2079468780,0.1717396877, 0.1549893311, 0.1765587853, 0.1720607392, 0.1952447037, 0.1890451919, 0.1680679084, 0.1886321105,0.1727215485,0.2079468780)
learner_data_set_means = as.data.frame(scr %>%
group_by(base_learner, data_set) %>%
summarize(mean_score = mean(test_score)
, stdev = sd(test_score)
, count = n()))
scr = readRDS('data/ml_scores_filtered2.RObject')
scr = scr[!grepl('\\_p[0-9]{1,2}', scr$data_set),] # Remove all results from the permutation test
scr[scr$test_score < 0, 'test_score'] = 0 # Set the cut off for the plot at 0 (so as good as, or worse than random)
learner_data_set_means = as.data.frame(scr %>%
group_by(base_learner, data_set) %>%
summarize(mean_score = mean(test_score)
, stdev = sd(test_score)
, count = n()))
mean(scr[scr$base_learner=='rfr' & scr$data_set=='x0_110110100', 'test_score'])
scr[scr$base_learner=='rfr' & scr$data_set=='x0_110110100', 'test_score']
mean(c(0.1717396877, 0.1549893311, 0.1765587853, 0.1720607392, 0.1952447037, 0.1890451919, 0.1680679084, 0.1886321105,0.1727215485,0.2079468780,0.1717396877, 0.1549893311, 0.1765587853, 0.1720607392, 0.1952447037, 0.1890451919, 0.1680679084, 0.1886321105,0.1727215485,0.2079468780))
?mean
mean(0.1717396877, 0.1549893311)
median(c(0.1717396877, 0.1549893311, 0.1765587853, 0.1720607392, 0.1952447037, 0.1890451919, 0.1680679084, 0.1886321105,0.1727215485,0.2079468780,0.1717396877, 0.1549893311, 0.1765587853, 0.1720607392, 0.1952447037, 0.1890451919, 0.1680679084, 0.1886321105,0.1727215485,0.2079468780))
CreateRpRatioPrediction()
predictions = GetRpRatioPredictions()
levels(predictions$col)
t.test(predictions[predictions$col=='Linear      | r² -0.02', "log_pred"], predictions[predictions$col=='COMP        | r² 0.20', "log_pred"])
print('Linear vs COMP: p = %s',t.test(predictions[predictions$col=='Linear      | r² -0.02', "log_pred"], predictions[predictions$col=='COMP        | r² 0.20', "log_pred"]))
print('Linear vs COMP: p = %f',t.test(predictions[predictions$col=='Linear      | r² -0.02', "log_pred"], predictions[predictions$col=='COMP        | r² 0.20', "log_pred"]))
sprintf('Linear vs COMP: p = %f',t.test(predictions[predictions$col=='Linear      | r² -0.02', "log_pred"], predictions[predictions$col=='COMP        | r² 0.20', "log_pred"]))
sprintf('Linear vs COMP: p = %f',t.test(predictions[predictions$col=='Linear      | r² -0.02', "log_pred"], predictions[predictions$col=='COMP        | r² 0.20', "log_pred"])$p.value)
sprintf('Linear vs COMP: p = %f',t.test(predictions[predictions$col=='Linear      | r² -0.02', "log_pred"], predictions[predictions$col=='COMP        | r² 0.20', "log_pred"])$p.value)
sprintf('COMP vs COMP rna.sr: p = %f',t.test(predictions[predictions$col=='COMP        | r² 0.20', "log_pred"], predictions[predictions$col=='COMP rna.sr | r² 0.20', "log_pred"]))
sprintf('COMP vs COMP rna.sr: p = %f',t.test(predictions[predictions$col=='COMP        | r² 0.20', "log_pred"], predictions[predictions$col=='COMP rna.sr | r² 0.20', "log_pred"])$p.value)
sprintf('COMP vs COMP rna.hl: p = %f',t.test(predictions[predictions$col=='COMP        | r² 0.20', "log_pred"], predictions[predictions$col=='COMP rna.hl | r² 0.21', "log_pred"])$p.value)
sprintf('COMP vs COMP pro.hl: p = %f',t.test(predictions[predictions$col=='COMP        | r² 0.20', "log_pred"], predictions[predictions$col=='COMP pro.hl | r² 0.21', "log_pred"])$p.value)
sprintf('COMP vs COMP rpf: p = %f',t.test(predictions[predictions$col=='COMP        | r² 0.20', "log_pred"], predictions[predictions$col=='COMP rpf    | r² 0.23', "log_pred"])$p.value)
sprintf('COMP vs COMP exp: p = %f',t.test(predictions[predictions$col=='COMP        | r² 0.20', "log_pred"], predictions[predictions$col=='COMP exp    | r² 0.24', "log_pred"])$p.value)
sprintf('RP ratio predictions significance:')
sprintf('Linear vs COMP: p = %f',t.test(predictions[predictions$col=='Linear      | r² -0.02', "log_pred"], predictions[predictions$col=='COMP        | r² 0.20', "log_pred"])$p.value)
sprintf('COMP vs COMP rna.sr: p = %f',t.test(predictions[predictions$col=='COMP        | r² 0.20', "log_pred"], predictions[predictions$col=='COMP rna.sr | r² 0.20', "log_pred"])$p.value)
sprintf('COMP vs COMP rna.hl: p = %f',t.test(predictions[predictions$col=='COMP        | r² 0.20', "log_pred"], predictions[predictions$col=='COMP rna.hl | r² 0.21', "log_pred"])$p.value)
sprintf('COMP vs COMP pro.hl: p = %f',t.test(predictions[predictions$col=='COMP        | r² 0.20', "log_pred"], predictions[predictions$col=='COMP pro.hl | r² 0.21', "log_pred"])$p.value)
sprintf('COMP vs COMP rpf: p = %f',t.test(predictions[predictions$col=='COMP        | r² 0.20', "log_pred"], predictions[predictions$col=='COMP rpf    | r² 0.23', "log_pred"])$p.value)
sprintf('COMP vs COMP exp: p = %f',t.test(predictions[predictions$col=='COMP        | r² 0.20', "log_pred"], predictions[predictions$col=='COMP exp    | r² 0.24', "log_pred"])$p.value)
txt = ''
txt = txt + 'aap'
sprintf(txt)
txt = paste( 'aap')
sprintf(txt)
txt = ''
txt = paste( 'aap\n')
txt = paste( 'noot\n')
sprintf(txt)
txt = ''
txt = paste(txt, 'aap\n')
txt = paste(txt, 'noot\n')
sprintf(txt)
print(txt)
predictions = GetProteinPredictions()
scr = readRDS('ml_scores_filtered.RObject')
scr = scr[!grepl('\\_p[0-9]{1,2}', scr$data_set),] # Remove all results from the permutation test
scr = scr[grepl('x0_', scr$data_set),]
scr = scr[scr$base_learner=='rfr',]
scr = readRDS('data/ml_scores_filtered.RObject')
scr = readRDS('data\ml_scores_filtered.RObject')
scr = readRDS('data/ml_scores_filtered.RObject')
scr = readRDS('data/ml_scores_filtered2.RObject')
scr = scr[!grepl('\\_p[0-9]{1,2}', scr$data_set),] # Remove all results from the permutation test
scr = scr[grepl('x0_', scr$data_set),]
scr = scr[scr$base_learner=='rfr',]
for(fs in unique(scr$data_set)){
p = t.test(scr[scr$data_set=='x0_110110100','test_score'],scr[scr$data_set==fs,'test_score'])$p.value
fs = PrettifyFeatureSetNames(fs)
print(paste(fs,"--- PVALUE: ", p))
}
sprintf('RP ratio predictions significance:')
for(fs in unique(predictions$col)){
p = t.test(predictions[predictions$col=='COMP        | r² 0.20','log_pred'],predictions[predictions$col==fs,'log_pred'])$p.value
fs = PrettifyFeatureSetNames(fs)
print(paste(paste('COMP vs ',fs),"--- PVALUE: ", p))
}
t.test(scr[scr$data_set=='x0_110110100','test_score'],scr[scr$data_set=='x0_110110100-0100','test_score'])$p.value
t.test(scr[scr$data_set=='x0_110110100','test_score'],scr[scr$data_set=='x0_110110100-0010','test_score'])$p.value
t.test(scr[scr$data_set=='x0_110110100','test_score'],scr[scr$data_set=='x0_110110100-0001','test_score'])$p.value
t.test(scr[scr$data_set=='x0_110110100','test_score'],scr[scr$data_set=='x0_110110100-1000','test_score'])$p.value
t.test(scr[scr$data_set=='x0_110110100','test_score'],scr[scr$data_set=='x0_110110100-1111','test_score'])$p.value
#### PROTEIN PREDICTIONS COMPARE (R2)
learner= 'rfr'
predictions = data.frame()
training_ids = read.table('./data/training_ids.csv', sep='\t', header=T, stringsAsFactors=F)
mrnas_p = readRDS('./data/mrnas_p.RObject')
feature_sets = c('linear_model', 'x0_110110100', 'x0_110110100-0100','x0_110110100-0010','x0_110110100-0001','x0_110110100-1000','x0_110110100-1111')
r2s = data.frame()
for(fs in feature_sets) {
#fs='linear_model'
for(i in 1:10){
#i = 1
#fs='linear_model'
train_ids = training_ids[training_ids[,sprintf('set_%s',i)]==T,'sys_id']
test_ids = training_ids[training_ids[,sprintf('set_%s',i)]==F,'sys_id']
if(fs=='linear_model'){
print('a')
mrnas_train = mrnas_p[mrnas_p$sys_id %in% train_ids,]
mrnas_test = mrnas_p[mrnas_p$sys_id %in% test_ids,]
m2 = lm(mrnas_train$avg_count_pro ~ mrnas_train$avg_count_rna)
real_values = mrnas_test$pro_per_rna
pred_values = rep(m2$coefficients[2], length(real_values))
pred_temp = data.frame(mrnas_test$sys_id, real_values, pred_values)
colnames(pred_temp) = c('sys_id','real','pred')
pred_temp$avg_count_pro = apply(pred_temp, 1, function(x) {  return(mrnas_p[mrnas_p$sys_id==x['sys_id'], 'avg_count_pro'])   }  )
pred_temp$avg_count_rna = apply(pred_temp, 1, function(x) {  return(mrnas_p[mrnas_p$sys_id==x['sys_id'], 'avg_count_rna'])   }  )
pred_temp$pred_pro = pred_temp$avg_count_rna * pred_temp$pred
pred_temp$clr = '#FF5577'
} else {
pred_temp = read.table(sprintf('./ml_output/ml_predictions_%s_%s_%s.csv', learner,fs,i),header=F,sep=',', stringsAsFactors=F)
pred_temp = cbind(as.data.frame(test_ids[1:951]), pred_temp, stringsAsFactors=F) # ORDER STAYED THE SAME
colnames(pred_temp) = c('sys_id','real','pred')
# DE-SCALE THE DATA
descaled_real = (pred_temp$real * sd(mrnas_p[mrnas_p$sys_id %in% train_ids, 'pro_per_rna'])) + mean(mrnas_p[mrnas_p$sys_id %in% train_ids, 'pro_per_rna'])
m = lm(mrnas_p[mrnas_p$sys_id %in% test_ids[1:951], 'pro_per_rna'] ~ descaled_real)
descaled_real = descaled_real * m$coefficients[2] + m$coefficients[1] # should match the real rp_ratio in the mrnas_p data set
pred_temp$real = descaled_real
descaled_pred = (pred_temp$pred * sd(mrnas_p[mrnas_p$sys_id %in% train_ids, 'pro_per_rna'])) + mean(mrnas_p[mrnas_p$sys_id %in% train_ids, 'pro_per_rna'])
descaled_pred = descaled_pred * m$coefficients[2] + m$coefficients[1] # De-scale using only the training data!
pred_temp$pred = as.numeric(as.character(descaled_pred))
pred_temp$clr = '#006666'
}
pred_temp$avg_count_pro = apply(pred_temp, 1, function(x) {  return(mrnas_p[mrnas_p$sys_id==x['sys_id'], 'avg_count_pro'])   }  )
pred_temp$avg_count_rna = apply(pred_temp, 1, function(x) {  return(mrnas_p[mrnas_p$sys_id==x['sys_id'], 'avg_count_rna'])   }  )
pred_temp$pred_pro = pred_temp$avg_count_rna * pred_temp$pred
pred_temp$log_avg_count_pro = log(pred_temp$avg_count_pro)
pred_temp$log_pred_pro = log(pred_temp$pred_pro)
r2s = rbind(r2s, data.frame(data_set=fs, test_set=i, r2=CalcR2(pred_temp$log_avg_count_pro, pred_temp$log_pred_pro)))
}
}
t.test(r2s[r2s$data_set=='x0_110110100','r2'],r2s[r2s$data_set=='x0_110110100-0100','r2'])$p.value
t.test(r2s[r2s$data_set=='x0_110110100','r2'],r2s[r2s$data_set=='x0_110110100-0010','r2'])$p.value
t.test(r2s[r2s$data_set=='x0_110110100','r2'],r2s[r2s$data_set=='x0_110110100-0001','r2'])$p.value
t.test(r2s[r2s$data_set=='x0_110110100','r2'],r2s[r2s$data_set=='x0_110110100-1000','r2'])$p.value
t.test(r2s[r2s$data_set=='x0_110110100','r2'],r2s[r2s$data_set=='x0_110110100-1111','r2'])$p.value
for(fs in unique(r2s$data_set)){
p = t.test(r2s[r2s$data_set=='x0_110110100','r2'],r2s[r2s$data_set==fs,'r2'])$p.value
fs = PrettifyFeatureSetNames(fs)
print(paste(fs,"--- PVALUE: ", p))
}
learner= 'rfr'
predictions = data.frame()
training_ids = read.table('./data/training_ids.csv', sep='\t', header=T, stringsAsFactors=F)
mrnas_p = readRDS('./data/mrnas_p.RObject')
feature_sets = c('linear_model', 'x0_110110100', 'x0_110110100-0100','x0_110110100-0010','x0_110110100-0001','x0_110110100-1000','x0_110110100-1111')
r2s = data.frame()
for(fs in feature_sets) {
#fs='linear_model'
for(i in 1:10){
#i = 1
#fs='linear_model'
train_ids = training_ids[training_ids[,sprintf('set_%s',i)]==T,'sys_id']
test_ids = training_ids[training_ids[,sprintf('set_%s',i)]==F,'sys_id']
if(fs=='linear_model'){
print('a')
mrnas_train = mrnas_p[mrnas_p$sys_id %in% train_ids,]
mrnas_test = mrnas_p[mrnas_p$sys_id %in% test_ids,]
m2 = lm(mrnas_train$avg_count_pro ~ mrnas_train$avg_count_rna)
real_values = mrnas_test$pro_per_rna
pred_values = rep(m2$coefficients[2], length(real_values))
pred_temp = data.frame(mrnas_test$sys_id, real_values, pred_values)
colnames(pred_temp) = c('sys_id','real','pred')
pred_temp$avg_count_pro = apply(pred_temp, 1, function(x) {  return(mrnas_p[mrnas_p$sys_id==x['sys_id'], 'avg_count_pro'])   }  )
pred_temp$avg_count_rna = apply(pred_temp, 1, function(x) {  return(mrnas_p[mrnas_p$sys_id==x['sys_id'], 'avg_count_rna'])   }  )
pred_temp$pred_pro = pred_temp$avg_count_rna * pred_temp$pred
pred_temp$clr = '#FF5577'
} else {
pred_temp = read.table(sprintf('./ml_output/predictions/ml_predictions_%s_%s_%s.csv', learner,fs,i),header=F,sep=',', stringsAsFactors=F)
pred_temp = cbind(as.data.frame(test_ids[1:951]), pred_temp, stringsAsFactors=F) # ORDER STAYED THE SAME
colnames(pred_temp) = c('sys_id','real','pred')
# DE-SCALE THE DATA
descaled_real = (pred_temp$real * sd(mrnas_p[mrnas_p$sys_id %in% train_ids, 'pro_per_rna'])) + mean(mrnas_p[mrnas_p$sys_id %in% train_ids, 'pro_per_rna'])
m = lm(mrnas_p[mrnas_p$sys_id %in% test_ids[1:951], 'pro_per_rna'] ~ descaled_real)
descaled_real = descaled_real * m$coefficients[2] + m$coefficients[1] # should match the real rp_ratio in the mrnas_p data set
pred_temp$real = descaled_real
descaled_pred = (pred_temp$pred * sd(mrnas_p[mrnas_p$sys_id %in% train_ids, 'pro_per_rna'])) + mean(mrnas_p[mrnas_p$sys_id %in% train_ids, 'pro_per_rna'])
descaled_pred = descaled_pred * m$coefficients[2] + m$coefficients[1] # De-scale using only the training data!
pred_temp$pred = as.numeric(as.character(descaled_pred))
pred_temp$clr = '#006666'
}
pred_temp$avg_count_pro = apply(pred_temp, 1, function(x) {  return(mrnas_p[mrnas_p$sys_id==x['sys_id'], 'avg_count_pro'])   }  )
pred_temp$avg_count_rna = apply(pred_temp, 1, function(x) {  return(mrnas_p[mrnas_p$sys_id==x['sys_id'], 'avg_count_rna'])   }  )
pred_temp$pred_pro = pred_temp$avg_count_rna * pred_temp$pred
pred_temp$log_avg_count_pro = log(pred_temp$avg_count_pro)
pred_temp$log_pred_pro = log(pred_temp$pred_pro)
r2s = rbind(r2s, data.frame(data_set=fs, test_set=i, r2=CalcR2(pred_temp$log_avg_count_pro, pred_temp$log_pred_pro)))
}
}
t.test(r2s[r2s$data_set=='x0_110110100','r2'],r2s[r2s$data_set=='x0_110110100-0100','r2'])$p.value
t.test(r2s[r2s$data_set=='x0_110110100','r2'],r2s[r2s$data_set=='x0_110110100-0010','r2'])$p.value
t.test(r2s[r2s$data_set=='x0_110110100','r2'],r2s[r2s$data_set=='x0_110110100-0001','r2'])$p.value
t.test(r2s[r2s$data_set=='x0_110110100','r2'],r2s[r2s$data_set=='x0_110110100-1000','r2'])$p.value
t.test(r2s[r2s$data_set=='x0_110110100','r2'],r2s[r2s$data_set=='x0_110110100-1111','r2'])$p.value
for(fs in unique(r2s$data_set)){
p = t.test(r2s[r2s$data_set=='x0_110110100','r2'],r2s[r2s$data_set==fs,'r2'])$p.value
fs = PrettifyFeatureSetNames(fs)
print(paste(fs,"--- PVALUE: ", p))
}
predictions = GetProteinPredictions()
predictions$diff = abs(predictions$log_avg_count_pro - predictions$log_pred_pro)
levels(predictions$col)
for(fs in unique(predictions$col)){
p = t.test(predictions[predictions$col=='COMP        | r² 0.58','diff'],predictions[predictions$col==fs,'diff'])$p.value
fs = PrettifyFeatureSetNames(fs)
print(paste(fs,"--- PVALUE: ", p))
}
for(fs in unique(predictions$col)){
p = t.test(predictions[predictions$col=='COMP        | r² 0.58','diff'],predictions[predictions$col==fs,'diff'])$p.value
#fs = PrettifyFeatureSetNames(fs)
print(paste(fs,"--- PVALUE: ", p))
}
# RP RATIO COMPARE BETWEEN LOG-SCALE DIFFERENCE FOR EACH TRANSCRIPT
predictions = GetRpRatioPredictions()
sprintf('COMPARE RP RATIO BETWEEN EACH TRANSCRIPT:')
sprintf('Linear vs COMP: p = %f',t.test(predictions[predictions$col=='Linear      | r² -0.02', "log_pred"], predictions[predictions$col=='COMP        | r² 0.20', "log_pred"])$p.value)
sprintf('COMP vs COMP rna.sr: p = %f',t.test(predictions[predictions$col=='COMP        | r² 0.20', "log_pred"], predictions[predictions$col=='COMP rna.sr | r² 0.20', "log_pred"])$p.value)
sprintf('COMP vs COMP rna.hl: p = %f',t.test(predictions[predictions$col=='COMP        | r² 0.20', "log_pred"], predictions[predictions$col=='COMP rna.hl | r² 0.21', "log_pred"])$p.value)
sprintf('COMP vs COMP pro.hl: p = %f',t.test(predictions[predictions$col=='COMP        | r² 0.20', "log_pred"], predictions[predictions$col=='COMP pro.hl | r² 0.21', "log_pred"])$p.value)
sprintf('COMP vs COMP rpf: p = %f',t.test(predictions[predictions$col=='COMP        | r² 0.20', "log_pred"], predictions[predictions$col=='COMP rpf    | r² 0.23', "log_pred"])$p.value)
sprintf('COMP vs COMP exp: p = %f',t.test(predictions[predictions$col=='COMP        | r² 0.20', "log_pred"], predictions[predictions$col=='COMP exp    | r² 0.24', "log_pred"])$p.value)
### RP RATIO COMPARE BETWEEN R2 FROM EACH TEST SET
scr = readRDS('data/ml_scores_filtered2.RObject')
scr = scr[!grepl('\\_p[0-9]{1,2}', scr$data_set),] # Remove all results from the permutation test
scr = scr[grepl('x0_', scr$data_set),]
scr = scr[scr$base_learner=='rfr',]
print('COMPARE RP RATIO R2 RESULTS')
for(fs in unique(scr$data_set)){
p = t.test(scr[scr$data_set=='x0_110110100','test_score'],scr[scr$data_set==fs,'test_score'])$p.value
fs = PrettifyFeatureSetNames(fs)
print(paste(fs,"--- PVALUE: ", p))
}
# PROTEIN PREDICTIONS COMPARE BETWEEN LOG-SCALE DIFFERENCE FOR EACH PROTEIN
predictions = GetProteinPredictions()
predictions$diff = abs(predictions$log_avg_count_pro - predictions$log_pred_pro)
for(fs in unique(predictions$col)){
p = t.test(predictions[predictions$col=='COMP        | r² 0.58','diff'],predictions[predictions$col==fs,'diff'])$p.value
#fs = PrettifyFeatureSetNames(fs)
print(paste(fs,"--- PVALUE: ", p))
}
sprintf('COMPARE PROTEIN PREDICTION BETWEEN EACH PREDICTED PROTEIN:')
t.test(predictions[predictions$col=='COMP | r² 0.57','log_avg_count_pro'], predictions[predictions$col=='COMP | r² 0.57','log_pred_pro'])$p.value
t.test(predictions[predictions$col=='COMP | r² 0.57','log_avg_count_pro'], predictions[predictions$col=='COMP rna.sr | r² 0.57','log_pred_pro'])$p.value
t.test(predictions[predictions$col=='COMP | r² 0.57','log_avg_count_pro'], predictions[predictions$col=='COMP rna.hl | r² 0.58','log_pred_pro'])$p.value
t.test(predictions[predictions$col=='COMP | r² 0.57','log_avg_count_pro'], predictions[predictions$col=='COMP pro.hl | r² 0.59','log_pred_pro'])$p.value
t.test(predictions[predictions$col=='COMP | r² 0.57','log_avg_count_pro'], predictions[predictions$col=='COMP rpf | r² 0.62','log_pred_pro'])$p.value
t.test(predictions[predictions$col=='COMP | r² 0.57','log_avg_count_pro'], predictions[predictions$col=='COMP exp. | r² 0.62','log_pred_pro'])$p.value
plot(predictions[predictions$col=='COMP | r² 0.57','log_avg_count_pro'], predictions[predictions$col=='COMP exp. | r² 0.62','log_pred_pro'])
#### PROTEIN PREDICTIONS COMPARE BETWEEN R2 FROM EACH TEST SET
learner= 'rfr'
predictions = data.frame()
training_ids = read.table('./data/training_ids.csv', sep='\t', header=T, stringsAsFactors=F)
mrnas_p = readRDS('./data/mrnas_p.RObject')
feature_sets = c('linear_model', 'x0_110110100', 'x0_110110100-0100','x0_110110100-0010','x0_110110100-0001','x0_110110100-1000','x0_110110100-1111')
r2s = data.frame()
for(fs in feature_sets) {
#fs='linear_model'
for(i in 1:10){
#i = 1
#fs='linear_model'
train_ids = training_ids[training_ids[,sprintf('set_%s',i)]==T,'sys_id']
test_ids = training_ids[training_ids[,sprintf('set_%s',i)]==F,'sys_id']
if(fs=='linear_model'){
print('a')
mrnas_train = mrnas_p[mrnas_p$sys_id %in% train_ids,]
mrnas_test = mrnas_p[mrnas_p$sys_id %in% test_ids,]
m2 = lm(mrnas_train$avg_count_pro ~ mrnas_train$avg_count_rna)
real_values = mrnas_test$pro_per_rna
pred_values = rep(m2$coefficients[2], length(real_values))
pred_temp = data.frame(mrnas_test$sys_id, real_values, pred_values)
colnames(pred_temp) = c('sys_id','real','pred')
pred_temp$avg_count_pro = apply(pred_temp, 1, function(x) {  return(mrnas_p[mrnas_p$sys_id==x['sys_id'], 'avg_count_pro'])   }  )
pred_temp$avg_count_rna = apply(pred_temp, 1, function(x) {  return(mrnas_p[mrnas_p$sys_id==x['sys_id'], 'avg_count_rna'])   }  )
pred_temp$pred_pro = pred_temp$avg_count_rna * pred_temp$pred
pred_temp$clr = '#FF5577'
} else {
pred_temp = read.table(sprintf('./ml_output/predictions/ml_predictions_%s_%s_%s.csv', learner,fs,i),header=F,sep=',', stringsAsFactors=F)
pred_temp = cbind(as.data.frame(test_ids[1:951]), pred_temp, stringsAsFactors=F) # ORDER STAYED THE SAME
colnames(pred_temp) = c('sys_id','real','pred')
# DE-SCALE THE DATA
descaled_real = (pred_temp$real * sd(mrnas_p[mrnas_p$sys_id %in% train_ids, 'pro_per_rna'])) + mean(mrnas_p[mrnas_p$sys_id %in% train_ids, 'pro_per_rna'])
m = lm(mrnas_p[mrnas_p$sys_id %in% test_ids[1:951], 'pro_per_rna'] ~ descaled_real)
descaled_real = descaled_real * m$coefficients[2] + m$coefficients[1] # should match the real rp_ratio in the mrnas_p data set
pred_temp$real = descaled_real
descaled_pred = (pred_temp$pred * sd(mrnas_p[mrnas_p$sys_id %in% train_ids, 'pro_per_rna'])) + mean(mrnas_p[mrnas_p$sys_id %in% train_ids, 'pro_per_rna'])
descaled_pred = descaled_pred * m$coefficients[2] + m$coefficients[1] # De-scale using only the training data!
pred_temp$pred = as.numeric(as.character(descaled_pred))
pred_temp$clr = '#006666'
}
pred_temp$avg_count_pro = apply(pred_temp, 1, function(x) {  return(mrnas_p[mrnas_p$sys_id==x['sys_id'], 'avg_count_pro'])   }  )
pred_temp$avg_count_rna = apply(pred_temp, 1, function(x) {  return(mrnas_p[mrnas_p$sys_id==x['sys_id'], 'avg_count_rna'])   }  )
pred_temp$pred_pro = pred_temp$avg_count_rna * pred_temp$pred
pred_temp$log_avg_count_pro = log(pred_temp$avg_count_pro)
pred_temp$log_pred_pro = log(pred_temp$pred_pro)
r2s = rbind(r2s, data.frame(data_set=fs, test_set=i, r2=CalcR2(pred_temp$log_avg_count_pro, pred_temp$log_pred_pro)))
}
}
source('~/School/Internship1/prot_pred/code/4_ml_results_analysis.r')
source('~/School/Internship1/prot_pred/code/4_ml_results_analysis.r')
CreateResultsTable()
predictions = GetRpRatioPredictions()
print(('COMPARE RP RATIO BETWEEN EACH TRANSCRIPT:'))
print('COMPARE RP RATIO R2 RESULTS')
for(fs in unique(predictions$col)){
p = t.test(predictions[predictions$col=='COMP        | r² 0.20','test_score'],predictions[predictions$col==fs,'test_score'])$p.value
#fs = PrettifyFeatureSetNames(fs)
print(paste(paste('COMP vs ',fs),"--- PVALUE: ", p))
}
predictions$diff = abs(predictions$log_real - predictions$log_pred)
print(('COMPARE RP RATIO BETWEEN EACH TRANSCRIPT:'))
for(fs in unique(predictions$col)){
p = t.test(predictions[predictions$col=='COMP        | r² 0.20','diff'],predictions[predictions$col==fs,'diff'])$p.value
#fs = PrettifyFeatureSetNames(fs)
print(paste(paste('COMP vs ',fs),"--- PVALUE: ", p))
}
CreateResultsTable = function(){
# RP RATIO COMPARE BETWEEN LOG-SCALE DIFFERENCE FOR EACH TRANSCRIPT
predictions = GetRpRatioPredictions()
predictions$diff = abs(predictions$log_real - predictions$log_pred)
print(('COMPARE RP RATIO BETWEEN EACH TRANSCRIPT:'))
for(fs in unique(predictions$col)){
p = t.test(predictions[predictions$col=='COMP        | r² 0.20','diff'],predictions[predictions$col==fs,'diff'])$p.value
#fs = PrettifyFeatureSetNames(fs)
print(paste(paste('COMP vs ',fs),"--- PVALUE: ", p))
}
print('')
### RP RATIO COMPARE BETWEEN R2 FROM EACH TEST SET
scr = readRDS('data/ml_scores_filtered2.RObject')
scr = scr[!grepl('\\_p[0-9]{1,2}', scr$data_set),] # Remove all results from the permutation test
scr = scr[grepl('x0_', scr$data_set),]
scr = scr[scr$base_learner=='rfr',]
print('COMPARE RP RATIO R2 RESULTS')
for(fs in unique(scr$data_set)){
p = t.test(scr[scr$data_set=='x0_110110100','test_score'],scr[scr$data_set==fs,'test_score'])$p.value
fs = PrettifyFeatureSetNames(fs)
print(paste(paste('COMP vs ',fs),"--- PVALUE: ", p))
}
print('')
# PROTEIN PREDICTIONS COMPARE BETWEEN LOG-SCALE DIFFERENCE FOR EACH PROTEIN
predictions = GetProteinPredictions()
predictions$diff = abs(predictions$log_avg_count_pro - predictions$log_pred_pro)
print('COMPARE PROTEIN PREDICTION BETWEEN EACH PREDICTED PROTEIN:')
for(fs in unique(predictions$col)){
p = t.test(predictions[predictions$col=='COMP        | r² 0.58','diff'],predictions[predictions$col==fs,'diff'])$p.value
#fs = PrettifyFeatureSetNames(fs)
print(paste(paste('COMP vs ',fs),"--- PVALUE: ", p))
}
print('')
#### PROTEIN PREDICTIONS COMPARE BETWEEN R2 FROM EACH TEST SET
learner= 'rfr'
predictions = data.frame()
training_ids = read.table('./data/training_ids.csv', sep='\t', header=T, stringsAsFactors=F)
mrnas_p = readRDS('./data/mrnas_p.RObject')
feature_sets = c('linear_model', 'x0_110110100', 'x0_110110100-0100','x0_110110100-0010','x0_110110100-0001','x0_110110100-1000','x0_110110100-1111')
r2s = data.frame()
for(fs in feature_sets) {
#fs='linear_model'
for(i in 1:10){
#i = 1
#fs='linear_model'
train_ids = training_ids[training_ids[,sprintf('set_%s',i)]==T,'sys_id']
test_ids = training_ids[training_ids[,sprintf('set_%s',i)]==F,'sys_id']
if(fs=='linear_model'){
mrnas_train = mrnas_p[mrnas_p$sys_id %in% train_ids,]
mrnas_test = mrnas_p[mrnas_p$sys_id %in% test_ids,]
m2 = lm(mrnas_train$avg_count_pro ~ mrnas_train$avg_count_rna)
real_values = mrnas_test$pro_per_rna
pred_values = rep(m2$coefficients[2], length(real_values))
pred_temp = data.frame(mrnas_test$sys_id, real_values, pred_values)
colnames(pred_temp) = c('sys_id','real','pred')
pred_temp$avg_count_pro = apply(pred_temp, 1, function(x) {  return(mrnas_p[mrnas_p$sys_id==x['sys_id'], 'avg_count_pro'])   }  )
pred_temp$avg_count_rna = apply(pred_temp, 1, function(x) {  return(mrnas_p[mrnas_p$sys_id==x['sys_id'], 'avg_count_rna'])   }  )
pred_temp$pred_pro = pred_temp$avg_count_rna * pred_temp$pred
pred_temp$clr = '#FF5577'
} else {
pred_temp = read.table(sprintf('./ml_output/predictions/ml_predictions_%s_%s_%s.csv', learner,fs,i),header=F,sep=',', stringsAsFactors=F)
pred_temp = cbind(as.data.frame(test_ids[1:951]), pred_temp, stringsAsFactors=F) # ORDER STAYED THE SAME
colnames(pred_temp) = c('sys_id','real','pred')
# DE-SCALE THE DATA
descaled_real = (pred_temp$real * sd(mrnas_p[mrnas_p$sys_id %in% train_ids, 'pro_per_rna'])) + mean(mrnas_p[mrnas_p$sys_id %in% train_ids, 'pro_per_rna'])
m = lm(mrnas_p[mrnas_p$sys_id %in% test_ids[1:951], 'pro_per_rna'] ~ descaled_real)
descaled_real = descaled_real * m$coefficients[2] + m$coefficients[1] # should match the real rp_ratio in the mrnas_p data set
pred_temp$real = descaled_real
descaled_pred = (pred_temp$pred * sd(mrnas_p[mrnas_p$sys_id %in% train_ids, 'pro_per_rna'])) + mean(mrnas_p[mrnas_p$sys_id %in% train_ids, 'pro_per_rna'])
descaled_pred = descaled_pred * m$coefficients[2] + m$coefficients[1] # De-scale using only the training data!
pred_temp$pred = as.numeric(as.character(descaled_pred))
pred_temp$clr = '#006666'
}
pred_temp$avg_count_pro = apply(pred_temp, 1, function(x) {  return(mrnas_p[mrnas_p$sys_id==x['sys_id'], 'avg_count_pro'])   }  )
pred_temp$avg_count_rna = apply(pred_temp, 1, function(x) {  return(mrnas_p[mrnas_p$sys_id==x['sys_id'], 'avg_count_rna'])   }  )
pred_temp$pred_pro = pred_temp$avg_count_rna * pred_temp$pred
pred_temp$log_avg_count_pro = log(pred_temp$avg_count_pro)
pred_temp$log_pred_pro = log(pred_temp$pred_pro)
r2s = rbind(r2s, data.frame(data_set=fs, test_set=i, r2=CalcR2(pred_temp$log_avg_count_pro, pred_temp$log_pred_pro)))
}
}
print('COMPARE PROTEIN PREDICTION R2 RESULTS')
for(fs in unique(r2s$data_set)){
p = t.test(r2s[r2s$data_set=='x0_110110100','r2'],r2s[r2s$data_set==fs,'r2'])$p.value
fs = PrettifyFeatureSetNames(fs)
print(paste(fs,"--- PVALUE: ", p))
}
}
CreateResultsTable()
tmp = function(){
print('a')
print('b')
print('c')
}
tmp()
